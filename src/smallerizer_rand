#!/usr/bin/env python

# Script that can be run on command line to shrink a large file by keeping n lines of the file, with random selection of lines (does not keep lines in order).  Based on the reservoir sampling method of keeping equal-probability of lines when total file size is unknown or when streaming continuous events.  Expected input is piped from stdin, ie if streaming from online source or very large file.


#Run example : cat inputfile.txt | smallerizer_rand 1000 outputfile.txt


import sys
import argparse
import random

def main(n_lines, outfile):
    output = []
    count = 0
    for line in sys.stdin:
        if count <= n_lines:
            output.append(line)
        if count > n_lines:
            j = random.randrange(count)
            if j <= n_lines:
                output[j] = line
        count += 1
    out = open(outfile,'w')
    for line in output:
        out.write(line)
    out.close()



if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument("n_lines")
    parser.add_argument("out_file")
    args = parser.parse_args()
    main(int(args.n_lines), args.out_file)
